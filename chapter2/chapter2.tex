\documentclass[../main.tex]{subfiles}

\begin{document}
\chapter{Differentialrechnung}\label{chp:differential}
Dieses Kapitel stellt den Hauptteil dieser Vorlesung dar.
Auch in~\cite{heuser} ist das korrespondierende
Kapitel XX bei weitem das grösste. Der Inhalt ist das
Studium differenzierbarer Abbildungen 
$f \colon \mathbb{R}^m \to \mathbb{R}^n$.
Die erste Schwierigkeit daran ist, dass der Ausdruck
\[
  \lim_{h \to 0} \frac{f(p + h) - f(p)}{h}
\]
für $m \geq 2$ keinen Sinn macht: Vektoren kann man nicht
definieren.

\section{Differenzierbarkeit}
\begin{definition}
  Sei $U \subset \mathbb{R}^m$ offen. Eine Abbildung
  $f \colon U \to \mathbb{R}^n$ heisst
  \emph{differenzierbar} im Punkt $p \in U$, falls
  folgendes existiert:
  \begin{enumerate}[(i)]
    \item eine lineare Abbildung 
      ${(Df)}_p \colon \mathbb{R}^m \to \mathbb{R}^n$,
      genannt \emph{Differential} von $f$ an
      der Stelle $p$,
    \item für alle $h \in \mathbb{R}^m$ mit $p + h \in U$ 
      ein \emph{Restterm} ${(Rf)}_p(h) \in \mathbb{R}^n$,
      der relativ klein in $\Vert h \Vert_2$ ist,
      so dass für alle $h \in \mathbb{R}^m$ mit $p + h \in U$ 
      gilt, dass
      \[
        f(p+h) = f(p) + {(Df)}_p(h) + {(Rf)}_p(h).
      \]
  \end{enumerate}
  Der Unterteilung von $f$ in diese drei Summanden sagt man
  \emph{Dreigliedentwicklung}. Die Forderung,
  dass ${(Rf)}_p(h)$ \emph{relativ klein} in $\Vert h \Vert_2$ 
  ist, bedeutet, dass
  \[
    \lim_{h \to 0} \frac{\Vert {(Rf)}_p(h)\Vert_2}{\Vert h \Vert_2}
    = 0.
  \]
  In anderen Worten existiert für alle $\varepsilon > 0$ ein $\delta > 0 $,
  so dass für alle $h \in \mathbb{R}^m$ mit $\Vert h \Vert_2
  \leq \delta$ gilt, dass $\Vert {(Rf)}_p(h) \Vert_2
  \leq \varepsilon \cdot \Vert h \Vert_2$.
\end{definition}

\begin{remark}
  Das Differential ist a priori nur für diejenigen
  $h$ definiert, für die $p + h$ noch in $U$ 
  liegt. Da $U$ aber offen ist, existiert aber
  eine Basis von $\mathbb{R}^m$ aus Vektoren
  $h_i$ für die $p + h_i$ noch in $U$ liegt.
  Da lineare Abbildungen durch die Bilder der
  Basisvektoren eindeutig bestimmt sind, lässt
  sich das Differential auf ganz $\mathbb{R}^m$
  erweitern.
\end{remark}

\begin{example}
  Sei $L \colon \mathbb{R}^m \to \mathbb{R}^n$ linear.
  Dann gilt für alle $p, h \in \mathbb{R}^m$,
  dass
  \[
    L(p + h) = L(p) + L(h).
  \]
  Dies ist eine Dreigliedentwicklung für $L$ 
  an der Stelle $p$ mit Restterm ${(RL)}_p(h) = 0$.
  Tatsächlich ist die Abbildung ${(DL)}_p = L$ linear.
  Die informale Erklärung dafür ist,
  dass~$L$ die ``beste lineare Approximation'' von $L$ 
  ist, und das an jeder Stelle.
\end{example}

\begin{examples}
  \leavevmode
  \begin{enumerate}[(1)]
    \item Betrachte die Funktion
      \begin{align*}
        f \colon \mathbb{R}^m & \to \mathbb{R} \\
        p & \mapsto \langle p, p \rangle.
      \end{align*}
      Für alle $p, h \in \mathbb{R}^m$ gilt, dass
      \[
        f(p+ h) = \langle p + h, p + h \rangle
        = \langle p, p \rangle + 2 \langle p, h \rangle + \langle h, h \rangle.
      \]
      Dies ist eine Dreigliedentwicklung für $f$ mit
      Differential
      ${(Df)}_p(h) = 2 \langle p, h \rangle$ und
      Restterm
      ${(Rf)}_p(h) = \langle h, h \rangle$.
      Tatsächlich ist ${(Df)}_p$ linear in $h$,
      da Skalarprodukte bilinear sind, und
      \[
        {(Rf)}_p(h) = \langle h, h \rangle = \Vert h \Vert_2^2
      \]
      ist relativ klein in $\Vert h \Vert_2$.
      Zum Beweis dafür sei $\varepsilon > 0$ und setze
      $\delta = \varepsilon$.
      Für alle $h \in \mathbb{R}^m$ mit $\Vert h \Vert_2 \leq \delta$ 
      gilt dann, dass
      \(
        |{(Rf)}_p(h)| = \Vert h \Vert_2^2 \leq \varepsilon \cdot \Vert h \Vert_2
      \).
    \item Betrachte die Abbildung
      \begin{align*}
        m \colon \mathbb{R}^2 & \to \mathbb{R} \\
        (x, y) & \mapsto xy.
      \end{align*}
      Seien $p = (p_1, p_2)$ und $h = (h_1, h_2)$ in $\mathbb{R}^2$.
      Dann gilt
      \[
        m(p + h) = (p_1 + h_1) \cdot (p_2 + h_2)
        = p_1 p_2 + (p_1 h_2 + p_2 h_1) + h_1 h_2.
      \]
      Dies ist eine Dreigliedentwicklung für $m$ bei $p$
      mit ${(Dm)}_p(h) = p_1 h_2 + p_2 h_1$ und
      ${(Rm)}_p(h) = h_1 h_2$.
      Da
      \[
        {(Dm)}_p(h) =
        \begin{pmatrix}
          p_2 & p_1
        \end{pmatrix}
        \begin{pmatrix}
          h_1 \\ h_2
        \end{pmatrix}
      \]
      gilt, ist ${(Dm)}_p$ linear.
      Weiter ist der Restterm 
      relativ klein in $\Vert h \Vert_2$, da
      \[
        |{(Rm)}_p(h)| = |h_1| \cdot |h_2| \leq \Vert h \Vert_2 \cdot
        \Vert h \Vert_2 = \Vert h \Vert_2^2,
      \]
      und $\Vert h \Vert_2^2$ ist nach Beispiel (1)
      relativ klein in $\Vert h \Vert_2$.
  \end{enumerate}
\end{examples}

Wir treffen nun die Kettenregel als Quelle
für viele Beispiele an.
Wir werden sie später in diesem Kapitel beweisen.

\begin{theorem*}[Kettenregel]
  Seien $U \subset \mathbb{R}^m$ und $V \subset \mathbb{R}^k$ 
  offen, und sei $f \colon U \to \mathbb{R}^k$ differenzierbar
  bei $p \in U$ mit $f(U) \subset V$,
  sowie $g \colon V \to \mathbb{R}^n$ bei $f(p) \in V$ 
  differenzierbar.
  Dann ist die Komposition $g \circ f \colon U \to \mathbb{R}^n$ 
  differenzierbar bei $p$, und es gilt
  \[
    {(D(g \circ f))}_p = {(Dg)}_{f(p)} \circ {(Df)}_p.
  \]
\end{theorem*}

\begin{example}
  Betrachte die Abbildung
  \begin{align*}
    \ell \colon \mathbb{R}^m & \to \mathbb{R} \\
    p & \mapsto \sqrt{\langle p, p \rangle}.
  \end{align*}
  In Koordinaten $x_1, \dots, x_m$ ist
   \[
     \ell(x_1, \dots, x_m) = \sqrt{x_1^2 + \cdots + x_m^2}.
  \]
  Sei $U = \mathbb{R}^m \setminus \{0\} \subset \mathbb{R}^m$ 
  und $V = \mathbb{R}_{>0}$.
  Beide dieser Mengen sind offen. Setze weiterhin
  \begin{align*}
    f \colon U & \to \mathbb{R} \\
    p & \mapsto \langle p, p \rangle
  \end{align*}
  und
  \begin{align*}
    g \colon \mathbb{R}_{>0} & \to \mathbb{R} \\
    t & \mapsto \sqrt t.
  \end{align*}
  Für alle $p \in U$ gilt $\ell(p) = g(f(p))$.
  Die Funktion $f$ ist differenzierbar in allen
  Punkten $p \in U$ 
  (eigentlich sogar in allen $p \in \mathbb{R}^n$).
  Ausserdem ist $g$ differenzierbar an allen Stellen
  $t > 0$.
  Aus der Analysis I wissen wir, dass
  \[
    {(Dg)}_t(h) = g'(t) \cdot h = \frac{1}{2 \sqrt t} \cdot h.
  \]
  Die Kettenregel liefert, dass
  $\ell = g \circ f$ an jeder Stelle $p \in U$ differenzierbar ist,
  und es gilt
  \[
    {(D \ell)}_p(h) = {(Dg)}_{f(p)}({(Df)}_p(h))
    = \frac{1}{2 \sqrt{\langle p, p \rangle}} \cdot 2 \langle p, h \rangle
    = \langle p / \Vert p \Vert_2, h \rangle.
  \]
  Der Vektor $p / \Vert p \Vert_2$ ist der Vektor mit Länge $1$,
  der in die selbe Richtung zeigt wie $p$.
  Er beschreibt den ``Zuwachs'' der Funktion $\ell$.
\end{example}

\begin{definition}
  Sei $f \colon \mathbb{R}^m \to \mathbb{R}^n$ eine Abbildung.
  Dann existieren eindeutige \emph{Komponentenfunktionen}
  $f_k \colon R^m \to \mathbb{R}$ 
  für $1 \leq k \leq n$ mit folgender Eigenschaft:
  für alle $p \in \mathbb{R}^m$ gilt, dass
  \[
    f(p) = \sum_{k=1}^{n} f_k(p) \cdot e_k.
  \]
\end{definition}

\begin{lemma}
  Eine Abbildung $f \colon \mathbb{R}^m \to \mathbb{R}^n$ ist differenzierbar,
  genau dann wenn alle Komponentenfunktionen 
  $f_k \colon \mathbb{R}^m \to \mathbb{R}$ bei $p$ differenzierbar sind.
\end{lemma}

\begin{proof}
  Um zu zeigen, dass die Komponentenfunktionen einer
  differenzierbaren Abbildung $f \colon \mathbb{R}^m \to \mathbb{R}^n$
  selbst differenzierbar sind, sei
  \[
    f(p + h) = f(p) + {(Df)}_p(h) + {(Rf)}_p(h)
  \]
  eine Dreigliedentwicklung von $f$.
  Für $1 \leq k \leq n$ 
  setze ${(Df_k)}_p(h) = \langle {(Df)}_p(h), e_k \rangle$ 
  und ${(Rf_k)}_p(h) = \langle {(Rf)}_p(h), e_k \rangle$.
  Dann gilt für alle $k \leq n$, dass
  \[
    f_k(p + h) = f_k(p) + {(Df_k)}_p(h) + {(Rf_k)}_p(h).
  \]
  Weiterhin ist
  \begin{enumerate}[(i)]
    \item die Funktion
      \begin{align*}
        {(Df_k)}_p \colon \mathbb{R}^m & \to \mathbb{R} \\
        h & \mapsto \langle {(Df)}_p(h), e_k \rangle
      \end{align*}
      als Verknüpfung einer linearen Funktion mit einer Projektion
      linear,
    \item der Restterm ${(Rf_k)}_p(h)$ relativ klein
      in $\Vert h \Vert_2$, da 
      \(
        |{(Rf_k)}_p(h)| \leq \Vert {(Rf)}_p(h) \Vert_2
      \)
      gilt.
  \end{enumerate}

  Umgekehrt nehmen wir an, dass die Komponentenfunktionen
  $f_k \colon \mathbb{R}^m \to \mathbb{R}$
  einer Funktion $f \colon \mathbb{R}^m \to \mathbb{R}^n$ 
  differenzierbar sind.
  Für alle $k$ gibt es dann eine Dreigliedentwicklung
  \(
    f_k(p + h) = f_k(p) + {(Df_k)}_p(h) + {(Rf_k)}_p(h).
  \)
  Setze
  \[
    {(Df)}_p(h) = \sum_{k=1}^{n} {(Df_k)}_p(h) \cdot e_k
  \]
  und
  \[
    {(Rf)}_p(h) = \sum_{k=1}^{n} {(Rf_k)}_p(h) \cdot e_k.
  \]
  Dann gilt
  \(
    f(p + h) = f(p) + {(Df)}_p(h) + {(Rf)}_p(h).
  \)
  Weiterhin ist
  \begin{enumerate}[(i)]
    \item die Abbildung
      \begin{align*}
        {(Df)}_p \colon \mathbb{R}^m & \to \mathbb{R}^n \\
        h & \mapsto \sum_{k=1}^{n} {(Df_k)}_p(h) \cdot e_k
      \end{align*}
      linear da Summen linearer Abbildungen linear sind, und
    \item ${(Rf)}_p(h)$ ist relativ klein in $\Vert h \Vert_2$,
      da
      \[
        \Vert {(Rf)}_p(h) \Vert_2 \leq \sum_{k=1}^{n} |{(Rf_k)}_p(h)|.
      \]
      Dies folgt aus der allgemeinen Ungleichung, dass
      die euklidische Norm immer kleiner ist als die Summennorm.
      Weiterhin verwenden wir, dass endliche Summen
      relativ kleiner Funktionen selbst relativ klein ist.
      Dazu teile $\varepsilon$ durch $n$ um ein geeignetes
      $\delta$ als Minimum $n$ verschiedener $\delta$ zu bekommen.
      \qedhere
  \end{enumerate}
\end{proof}

\begin{question}
  Können wir die Differenzierbarkeit von Abbildungen
  $f \colon \mathbb{R}^m \to \mathbb{R}$ weiter 
  auf die Differenzierbarkeit von Funktionen
  $g \colon \mathbb{R} \to \mathbb{R}$ zurückführen?
  Konkreter: Ist $f \colon \mathbb{R}^m \to \mathbb{R}$ 
  bei $p = 0$ differenzierbar, falls die Einschränkung
  von $f$ auf allen Koordinatenachsen differenzierbar ist?
\end{question}

Die Antwort hier ist leider ``nein'', wie in folgendem
Beispiel zu erkennen ist.

\begin{example}
  Betrachte die Funktion
  \begin{align*}
    f \colon \mathbb{R}^2 & \to \mathbb{R} \\
    (x, y) & \mapsto 
    \begin{cases}
      \frac{xy}{x^2 + y^2} & (x, y) \neq (0, 0) \\
      0 & (x, y) = (0, 0).
    \end{cases}
  \end{align*}
  Die Einschränkung von $f$ auf beide Achsen ist identisch null,
  also differenzierbar. Aber $f$ ist nicht einmal stetig im Nullpunkt:
  \[
    \lim_{n \to \infty} f(1/n, 1/n) = \frac{1}{2} \neq f(0, 0).
  \]
  Vergleiche auch Serie 6 für ein Beispiel einer Funktion, die
  trotz Stetigkeit im Nullpunkt dort nicht differenzierbar ist.
\end{example}

\begin{remark}
  Falls $f$ an der Stelle $p \in U$ eine
  Dreigliedentwicklung besitzt,
  dann ist diese eindeutig.
  Insbesondere ist das Differential 
  ${(Df)}_p \colon \mathbb{R}^m \to \mathbb{R}^n$ 
  wohldefiniert.
  Der Grund für die Eindeutigkeit des Differentials
  liegt darin, dass nur die Nullfunktion
  gleichzeitig linear und relativ klein ist.
  Man kann zeigen, dass die Differenz
  zweier potentiellen Differentialen derselben Funktion
  diese Eigenschaften erfüllt.
  Die Details dazu werden in Serie 7 behandelt.
\end{remark}

\begin{definition}
  Das Differential ${(Df)}_p \colon \mathbb{R}^m \to \mathbb{R}^n$ 
  einer differenzierbaren Funktion $f$
  ist linear,
  hat also bezüglich der Standardbasen auf
  $\mathbb{R}^m$ und $\mathbb{R}^n$ eine
  Abbildungsmatrix ${(Jf)}_p \in \mathbb{R}^{n \times m}$,
  genannt \emph{Jakobimatrix} von $f$ an der
  Stelle $p \in U$.
\end{definition}

Wir bestimmen nun die Einträge der Jakobimatrix
${(Jf)}_p$.
Schreibe wie üblich
\[
  f(p) = \sum_{k=1}^{n} f_k(p) e_k.
\]
Die Koeffizienten von ${(Jf)}_p$ sind dann
\begin{align*}
  {({(Jf)}_p)}_{ij} 
  &= \langle {(Df)}_p(e_j), e_i \rangle  \\
  &= \left\langle 
    \sum_{k=1}^{n} {(Df_k)}_p(e_j) e_k,
    e_i
  \right\rangle \\
  &= {(Df_i)}_p(e_j).
\end{align*}

\begin{definition}
  Sei $U \subset \mathbb{R}^m$ offen und
  $f \colon U \to \mathbb{R}^n$ differenzierbar.
  Die $j$-te \emph{partielle Ableitung}
  von $f_i \colon \mathbb{R}^m \to \mathbb{R}$ ist
  gegeben durch
  \[
    \frac{\partial f_i}{\partial x_j}(p) = {(Df_i)}_p(e_j) \in \mathbb{R}.
  \]
\end{definition}

Gemäss dieser Definition ist dann
\[
  {(Jf)}_p =
  \begin{pmatrix}
    {\partial f_1}/{\partial x_1}(p)
    & {\partial f_1}/{\partial x_2}(p)
    & \cdots
    &{\partial f_1}/{\partial x_m}(p)
    \\
    {\partial f_2}/{\partial x_1}(p)
    & {\partial f_2}/{\partial x_2}(p)
    & \cdots
    & {\partial f_2}/{\partial x_m}(p)\\
    \vdots & \vdots & \ddots & \vdots \\
    \partial f_n / \partial x_1 (p)
    & \partial f_n / \partial x_2 (p)
    & \cdots
    & \partial f_n / \partial x_m(p)
  \end{pmatrix}.
\]
Im Spezialfall $n = 1$, das heisst,
dass $f \colon \mathbb{R}^m \to \mathbb{R}$ 
skalare Werte annimmt, erhalten wir
einen Zeilenvektor ${(Jf)}_p$.
Der transponierte Vektor
 \[
   {(\nabla f)}_p =
   \begin{pmatrix}
     \partial f / \partial x_1 (p) \\
     \vdots \\
     \partial f/ \partial x_m (p)
   \end{pmatrix}
   \in \mathbb{R}^m
\]
heisst \emph{Gradient} von $f$ bei $p$.
Es gilt
\[
  {(Df)}_p(v) = \langle {(\nabla f)}_p, v \rangle.
\]

\begin{examples}
  \leavevmode
  \begin{enumerate}[(1)]
    \item Betrachte die Funktion
      \begin{align*}
        f \colon \mathbb{R}^m & \to \mathbb{R} \\
        p & \mapsto \langle p, p \rangle.
      \end{align*}
      In Koordinaten ist
      \[
        f(x_1, x_2, \dots, x_m) = x_1^2 + x_2^2 + \cdots + x_m^2
      \]
      und es gilt
      \[
        {(\nabla f)}_p =
        \begin{pmatrix}
          2x_1 \\
          2x_2 \\
          \vdots \\
          2x_m
        \end{pmatrix}
        = 2p.
      \]
    \item Betrachte die Funktion
      \begin{align*}
        f \colon \mathbb{R}^m & \to \mathbb{R} \\
        p & \mapsto \sqrt{\langle p, p \rangle} = \Vert p \Vert_2.
      \end{align*}
      Dann gilt
      \[
        {(Df)}_p(v) = \left\langle \frac{p}{\Vert p \Vert_2}, v \right\rangle,
      \]
      also ist
      \[
        {(\nabla f)}_p = \frac{p}{\Vert p \Vert_2}.
      \]
      In Koordinaten liest sich das als
      \[
        {(\nabla f)}_{(x_1, \dots, x_m)} 
        = \frac{1}{\sqrt{x_1^2 + \cdots + x_m^2}}
        \begin{pmatrix}
          x_1 \\
          \vdots\\
          x_m
        \end{pmatrix},
      \]
      wobei $f(x_1, \dots, x_m) = \sqrt{x_1^2 + \cdots + x_m^2}$.
    \item Betrachte die Funktion
      \begin{align*}
        f \colon \mathbb{R}^2 & \to \mathbb{R} \\
        (x, y) & \mapsto xy.
      \end{align*}
      Es gilt dann
      \[
        {(Df)}_p(v) = y v_1 + x v_2.
      \]
      Also ist
      \[
        {(\nabla f)}_{(x, y)} =
        \begin{pmatrix}
          y \\ x
        \end{pmatrix}.
      \]
  \end{enumerate}
\end{examples}

Mithilfe folgender Proposition können wir ${(Df)}_p(v)$ 
für beliebige $v \in \mathbb{R}^n$ ausrechnen.
Insbesondere liefert sie Möglichkeiten für die
Berechnung der Partiellen Ableitungen
$\partial f / \partial x_i (p) = {(Df)}_p(e_i)$.

\begin{proposition*}
  Sei $f \colon \mathbb{R}^m \to \mathbb{R}$ differenzierbar
  an der Stelle $p \in \mathbb{R}^m$.
  Dann gilt für alle $v \in \mathbb{R}^m$, dass
  \[
    {(Df)}_p(v) = \lim_{t \to 0}
    \frac{f(p + tv) - f(p)}{t}.
  \]
\end{proposition*}

\begin{proof}
  Falls $v = 0$ gilt, dann gilt
  \[
    {(Df)}_p(0) = 0 = \lim_{t \to 0} \frac{f(p) - f(p)}{t}.
  \]
  Für $v \neq 0$ folgt aus der Dreigliedentwicklung
  bei $p$, dass
  \[
    f(p + tv)  f(p)
    = {(Df)}_p(tv) + {(Rf)}_p(tv).
  \]
  Mithilfe der Linearität folgern wir, dass
  \[
    {(Df)}_p(v) = \frac{f(p + tv) - f(p)}{t} - \frac{{(Rf)}_p(tv)}{t}.
  \]
  Sei $\varepsilon > 0$ vorgegeben. Wähle $\delta > 0$ 
  so, dass für alle $h$ mit $\Vert h \Vert_2 \leq \delta$ 
  gilt, dass $\Vert {(Rf)}_p(h) \Vert_2 \leq \varepsilon \cdot
  \Vert h \Vert_2 / \Vert v \Vert_2$.
  Für $t \leq \delta / \Vert v \Vert_2$ gilt dann,
  dass $\Vert tv \Vert_2 \leq \delta$,
  also gilt auch, dass
  $\Vert {(Rf)}_p (tv) \leq \varepsilon 
  \cdot \Vert t v \Vert_2 /\Vert v \Vert_2$.
  Wir schliessen, dass
  \[
    \left\Vert \frac{{(Rf)}_p(tv)}{t} \right\Vert
    \leq \frac{\varepsilon \cdot \Vert v \Vert_2}{\Vert v \Vert_2} 
    = \varepsilon.
  \]
  In anderen Worten ist
  \[
    \lim_{t \to 0} \frac{{(Rf)}_p(tv)}{t} = 0. \qedhere
  \]
\end{proof}

\begin{remark}
  Die Existenz des Grenzwerts
  \[
    \lim_{t \to 0} \frac{f(p + tv) - f(p)}{t}
  \]
  für alle $v \in \mathbb{R}^m$ impliziert nicht
  die Differenzierbarkeit von $f$ an der Stelle $p$.
\end{remark}

\begin{example}
  Die Funktion
  \begin{align*}
    f \colon \mathbb{R}^2 & \to \mathbb{R} \\
    (x, y) & \mapsto \frac{xy(x-y)}{x^2 + y^2}
  \end{align*}
  ist nicht differenzierbar bei $p = 0$,
  obwohl die Funktion auf allen eindimensionalen Untervektorräumen
  von $\mathbb{R}^2$ linear ist.
  Siehe Serie 6 für die Details.
\end{example}


\end{document}
